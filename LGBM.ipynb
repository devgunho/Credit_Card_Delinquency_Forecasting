{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T19:08:25.388003Z",
     "start_time": "2021-04-06T19:08:24.065143Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T18:57:58.370236Z",
     "start_time": "2021-04-06T18:57:58.365725Z"
    }
   },
   "source": [
    "### Data Load & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T19:08:25.462913Z",
     "start_time": "2021-04-06T19:08:25.388997Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset/train.csv')\n",
    "train = train.drop(['index'], axis=1)\n",
    "train.fillna('NAN', inplace=True)\n",
    "\n",
    "test = pd.read_csv('dataset/test.csv')\n",
    "test = test.drop(['index'], axis=1)\n",
    "test.fillna('NAN', inplace=True)\n",
    "\n",
    "submit = pd.read_csv('dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T19:08:25.477867Z",
     "start_time": "2021-04-06T19:08:25.463872Z"
    }
   },
   "outputs": [],
   "source": [
    "object_col = []\n",
    "for col in train.columns:\n",
    "    if train[col].dtype == 'object':\n",
    "        object_col.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T19:08:25.538497Z",
     "start_time": "2021-04-06T19:08:25.478334Z"
    }
   },
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(train.loc[:, object_col])\n",
    "\n",
    "train_onehot_df = pd.DataFrame(enc.transform(train.loc[:,\n",
    "                                                       object_col]).toarray(),\n",
    "                               columns=enc.get_feature_names(object_col))\n",
    "train.drop(object_col, axis=1, inplace=True)\n",
    "train = pd.concat([train, train_onehot_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T19:08:25.569022Z",
     "start_time": "2021-04-06T19:08:25.538957Z"
    }
   },
   "outputs": [],
   "source": [
    "test_onehot_df = pd.DataFrame(enc.transform(test.loc[:, object_col]).toarray(),\n",
    "                              columns=enc.get_feature_names(object_col))\n",
    "test.drop(object_col, axis=1, inplace=True)\n",
    "test = pd.concat([test, test_onehot_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T19:00:52.439475Z",
     "start_time": "2021-04-06T19:00:52.430499Z"
    }
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T19:08:25.584071Z",
     "start_time": "2021-04-06T19:08:25.570022Z"
    }
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "folds = []\n",
    "for train_idx, valid_idx in skf.split(train, train['credit']):\n",
    "    folds.append((train_idx, valid_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T19:08:30.894936Z",
     "start_time": "2021-04-06T19:08:25.585070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================1============================================\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_logloss: 0.649825\tvalid_1's multi_logloss: 0.754342\n",
      "[200]\ttraining's multi_logloss: 0.565196\tvalid_1's multi_logloss: 0.738368\n",
      "[300]\ttraining's multi_logloss: 0.503465\tvalid_1's multi_logloss: 0.731678\n",
      "[400]\ttraining's multi_logloss: 0.451777\tvalid_1's multi_logloss: 0.730029\n",
      "Early stopping, best iteration is:\n",
      "[429]\ttraining's multi_logloss: 0.438088\tvalid_1's multi_logloss: 0.729175\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================2============================================\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_logloss: 0.646021\tvalid_1's multi_logloss: 0.764365\n",
      "[200]\ttraining's multi_logloss: 0.560632\tvalid_1's multi_logloss: 0.751211\n",
      "[300]\ttraining's multi_logloss: 0.497513\tvalid_1's multi_logloss: 0.748437\n",
      "Early stopping, best iteration is:\n",
      "[330]\ttraining's multi_logloss: 0.480923\tvalid_1's multi_logloss: 0.747248\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================3============================================\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_logloss: 0.650293\tvalid_1's multi_logloss: 0.758441\n",
      "[200]\ttraining's multi_logloss: 0.562092\tvalid_1's multi_logloss: 0.744718\n",
      "[300]\ttraining's multi_logloss: 0.497577\tvalid_1's multi_logloss: 0.742915\n",
      "Early stopping, best iteration is:\n",
      "[300]\ttraining's multi_logloss: 0.497577\tvalid_1's multi_logloss: 0.742915\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================4============================================\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_logloss: 0.648708\tvalid_1's multi_logloss: 0.755516\n",
      "[200]\ttraining's multi_logloss: 0.562289\tvalid_1's multi_logloss: 0.7392\n",
      "[300]\ttraining's multi_logloss: 0.500311\tvalid_1's multi_logloss: 0.736786\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttraining's multi_logloss: 0.525232\tvalid_1's multi_logloss: 0.735804\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================5============================================\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_logloss: 0.651188\tvalid_1's multi_logloss: 0.755536\n",
      "[200]\ttraining's multi_logloss: 0.565233\tvalid_1's multi_logloss: 0.741456\n",
      "[300]\ttraining's multi_logloss: 0.500595\tvalid_1's multi_logloss: 0.736311\n",
      "Early stopping, best iteration is:\n",
      "[289]\ttraining's multi_logloss: 0.50667\tvalid_1's multi_logloss: 0.735772\n",
      "================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "lgb_models = {}\n",
    "for fold in range(5):\n",
    "    print(\n",
    "        f'===================================={fold+1}============================================'\n",
    "    )\n",
    "    train_idx, valid_idx = folds[fold]\n",
    "    X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n",
    "                                         train['credit'][train_idx].values, train['credit'][valid_idx].values\n",
    "    lgb = LGBMClassifier(n_estimators=1000)\n",
    "    lgb.fit(X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose=100)\n",
    "    lgb_models[fold] = lgb\n",
    "    print(\n",
    "        f'================================================================================\\n\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T19:08:31.195160Z",
     "start_time": "2021-04-06T19:08:30.895934Z"
    }
   },
   "outputs": [],
   "source": [
    "submit.iloc[:, 1:] = 0\n",
    "for fold in range(5):\n",
    "    submit.iloc[:, 1:] += lgb_models[fold].predict_proba(test) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T19:08:31.269960Z",
     "start_time": "2021-04-06T19:08:31.196158Z"
    }
   },
   "outputs": [],
   "source": [
    "submit.to_csv('./submit/submit_20210407_01.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T19:08:31.299880Z",
     "start_time": "2021-04-06T19:08:31.270958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26457</td>\n",
       "      <td>0.047811</td>\n",
       "      <td>0.105655</td>\n",
       "      <td>0.846533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26458</td>\n",
       "      <td>0.246816</td>\n",
       "      <td>0.141146</td>\n",
       "      <td>0.612038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26459</td>\n",
       "      <td>0.038839</td>\n",
       "      <td>0.104809</td>\n",
       "      <td>0.856351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26460</td>\n",
       "      <td>0.103354</td>\n",
       "      <td>0.131802</td>\n",
       "      <td>0.764844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26461</td>\n",
       "      <td>0.099892</td>\n",
       "      <td>0.174582</td>\n",
       "      <td>0.725526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26462</td>\n",
       "      <td>0.050025</td>\n",
       "      <td>0.128024</td>\n",
       "      <td>0.821951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26463</td>\n",
       "      <td>0.485439</td>\n",
       "      <td>0.514189</td>\n",
       "      <td>0.000372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26464</td>\n",
       "      <td>0.117118</td>\n",
       "      <td>0.144094</td>\n",
       "      <td>0.738789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26465</td>\n",
       "      <td>0.073126</td>\n",
       "      <td>0.129800</td>\n",
       "      <td>0.797073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26466</td>\n",
       "      <td>0.061997</td>\n",
       "      <td>0.264591</td>\n",
       "      <td>0.673412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>26467</td>\n",
       "      <td>0.094204</td>\n",
       "      <td>0.170662</td>\n",
       "      <td>0.735134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26468</td>\n",
       "      <td>0.085369</td>\n",
       "      <td>0.143616</td>\n",
       "      <td>0.771015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26469</td>\n",
       "      <td>0.303588</td>\n",
       "      <td>0.151621</td>\n",
       "      <td>0.544792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26470</td>\n",
       "      <td>0.062196</td>\n",
       "      <td>0.158058</td>\n",
       "      <td>0.779747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>26471</td>\n",
       "      <td>0.102518</td>\n",
       "      <td>0.231369</td>\n",
       "      <td>0.666112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>26472</td>\n",
       "      <td>0.089760</td>\n",
       "      <td>0.220212</td>\n",
       "      <td>0.690028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>26473</td>\n",
       "      <td>0.083097</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>0.785703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26474</td>\n",
       "      <td>0.330405</td>\n",
       "      <td>0.669426</td>\n",
       "      <td>0.000170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26475</td>\n",
       "      <td>0.252474</td>\n",
       "      <td>0.265311</td>\n",
       "      <td>0.482215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26476</td>\n",
       "      <td>0.029685</td>\n",
       "      <td>0.115700</td>\n",
       "      <td>0.854615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index         0         1         2\n",
       "0   26457  0.047811  0.105655  0.846533\n",
       "1   26458  0.246816  0.141146  0.612038\n",
       "2   26459  0.038839  0.104809  0.856351\n",
       "3   26460  0.103354  0.131802  0.764844\n",
       "4   26461  0.099892  0.174582  0.725526\n",
       "5   26462  0.050025  0.128024  0.821951\n",
       "6   26463  0.485439  0.514189  0.000372\n",
       "7   26464  0.117118  0.144094  0.738789\n",
       "8   26465  0.073126  0.129800  0.797073\n",
       "9   26466  0.061997  0.264591  0.673412\n",
       "10  26467  0.094204  0.170662  0.735134\n",
       "11  26468  0.085369  0.143616  0.771015\n",
       "12  26469  0.303588  0.151621  0.544792\n",
       "13  26470  0.062196  0.158058  0.779747\n",
       "14  26471  0.102518  0.231369  0.666112\n",
       "15  26472  0.089760  0.220212  0.690028\n",
       "16  26473  0.083097  0.131200  0.785703\n",
       "17  26474  0.330405  0.669426  0.000170\n",
       "18  26475  0.252474  0.265311  0.482215\n",
       "19  26476  0.029685  0.115700  0.854615"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
